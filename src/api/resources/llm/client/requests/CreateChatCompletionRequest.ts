/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Vectara from "../../../../index.js";

/**
 * @example
 *     {
 *         model: "model",
 *         messages: [{
 *                 role: "role",
 *                 content: "content"
 *             }]
 *     }
 */
export interface CreateChatCompletionRequest {
    /**
     * The API will make a best effort to complete the request in the specified seconds or time out.
     */
    "Request-Timeout"?: number;
    /**
     * The API will make a best effort to complete the request in the specified milliseconds or time out.
     */
    "Request-Timeout-Millis"?: number;
    /** The ID of the model to use. This field is required. */
    model: string;
    /** An ordered array of messages that represent the full context of the conversation to date. Each message includes a `role` and `content`. */
    messages: Vectara.ChatCompletionRequestMessage[];
    /** Optional. When set to `true`, the API streams partial message deltas as they become available, similar to ChatGPT's streaming mode. */
    stream?: boolean;
}
