/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Vectara from "../index";

/**
 * Full response to a chat question when the result is not streamed.
 */
export interface ChatFullResponse {
    /** If the chat response was stored, the ID of the chat. */
    chatId?: string;
    /** If the chat response was stored, the ID of the turn. */
    turnId?: string;
    /** The message from the chat model for the chat message. */
    answer?: string;
    /** The language that the answer is expected to be. */
    responseLanguage?: Vectara.Language;
    /** The ranked search results that the chat model used. */
    searchResults?: Vectara.IndividualSearchResult[];
    /** The probability that the summary is factually consistent with the results. */
    factualConsistencyScore?: number;
    /**
     * The rendered prompt sent to the LLM. Useful when creating customer `prompt_text` templates. Only available
     * to Scale customers.
     */
    renderedPrompt?: string;
    /**
     * If you are on the Scale plan, you can view the actual query made to backend that was rephrased
     * by the LLM from the input query.
     */
    rephrasedQuery?: string;
}
