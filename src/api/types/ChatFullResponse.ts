/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Vectara from "../index";

/**
 * Full response to a chat question when the result is not streamed.
 */
export interface ChatFullResponse {
    /** If the chat response was stored, the ID of the chat. */
    chatId?: string;
    /** If the chat response was stored, the ID of the turn. */
    turnId?: string;
    /** The message from the chat model for the chat message. */
    answer?: string;
    /** The language that the answer is expected to be. */
    responseLanguage?: Vectara.Language;
    /** The ranked search results that the chat model used. */
    searchResults?: Vectara.IndividualSearchResult[];
    /**
     * Indicates the probability that the summary is factually consistent with the results.
     * The system excludes this property if it encounters excessively large outputs or search
     * results.
     */
    factualConsistencyScore?: number;
    /** The rendered prompt sent to the LLM. Useful when creating customer `prompt_template` templates. */
    renderedPrompt?: string;
    /** Non-fatal warnings that occurred during request processing */
    warnings?: Vectara.QueryWarning[];
    /**
     * View the actual query made to backend that was rephrased
     * by the LLM from the input query.
     */
    rephrasedQuery?: string;
}
